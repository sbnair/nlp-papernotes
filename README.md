# nlp-papernotes

> Reading NLP-related papers when working, summary and thoughts. Major in Machine Reading Comprehension (MRC), Question Answering (QA), Multi-document MRC, Information Retriever (IR) and Ranking.

## Basic Concepts

- **LSA**, references in [Wikipedia](https://en.wikipedia.org/wiki/Latent_semantic_analysis), [An Introduction to Latent Semantic Analysis](https://www.asc.ohio-state.edu/reidy.16/LSAtutorial.pdf), [Indexing by Latent Semantic Analysis](http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf), CUHK [Latent Semantic Indexing (LSI) An Example](http://www1.se.cuhk.edu.hk/~seem5680/lecture/LSI-Eg.pdf), CUHK [PPT](http://www1.se.cuhk.edu.hk/~seem5680/lecture/latent-semantic-model-2016.pdf), Stanford NLP IR-book [latent-semantic-indexing](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html).
- **LDA**, references in [Wikipedia](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), [LDA Topic Modeling: An Explanation](https://towardsdatascience.com/lda-topic-modeling-an-explanation-e184c90aadcd), [Topic Modeling and Latent Dirichlet Allocation (LDA) in Python](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24), Paper [Latent Dirichlet Allocation](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf), [Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d), [Topic modeling using Latent Dirichlet Allocation(LDA) and Gibbs Sampling explained!](https://medium.com/analytics-vidhya/topic-modeling-using-lda-and-gibbs-sampling-explained-49d49b3d1045), [Topic Modeling with Gensim (Python)](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/).
- **SVD**, references in [Wikipedia](https://en.wikipedia.org/wiki/Singular_value_decomposition), 

## Language Model

Visiting [Tomas Mikolov](https://scholar.google.com/citations?user=oBu8kMMAAAAJ&hl=en) Google Scholar to get related papers. 

Other papers list:

- [A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)

BERT-style Models, Summary [PPT](#).

- [BERT](#)
- [XLNet](#)
- [structBERT](#)
- [spanBERT](#)
- [SemBERT](#)
- [RoBERTa](#)
- [ALBERT](#)

## MRC & QA

Summary [PPT](#).

### ACL 2019
- [RE3QA](#)
- [RankQA](#)

## Knowledge Distillation (KD)
KD is similar to [Label Smoothing](https://medium.com/@nainaakash012/when-does-label-smoothing-help-89654ec75326), introduction of KD from the following blogs:

- [Neural Network Distiller](https://nervanasystems.github.io/distiller/knowledge_distillation.html)
- [Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)
- [Tap into the dark knowledge using neural nets — Knowledge distillation](https://towardsdatascience.com/knowledge-distillation-and-the-concept-of-dark-knowledge-8b7aed8014ac)
- [Knowledge Distillation](https://medium.com/neuralmachine/knowledge-distillation-dc241d7c2322)

## MS MARCO
MS MARCO [LeaderBoard](http://www.msmarco.org/leaders.aspx), several public paper models, written on Github [MSMARCO-MRC-Analysis](https://github.com/IndexFziQ/MSMARCO-MRC-Analysis)

### Passage Retrieval
- Duet: [[arxiv](https://arxiv.org/abs/1610.08136)], [[PPT](#)], [[notes](#)] 
- [Duet V2](#)

## Optimizer
- [Adam](#) TODO

## Bookshelf
- 《[Deep Learning](http://www.deeplearningbook.org/)》
- 《[Deep Learning (中文版)](https://exacity.github.io/deeplearningbook-chinese/)》
- 《[Mathematics for Machine Learning](https://mml-book.github.io/)》
- 《[Learning to rank for information retrieval](https://www.cda.cn/uploadfile/image/20151220/20151220115436_46293.pdf)》
- 《[GDL-Generative Deep Learning](https://github.com/yongbowin/nlp-papernotes/tree/master/books/GDL-Generative_Deep_Learning-David_Foster.pdf)》
- 《[Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/)》
- 《[word2vec math theories](https://github.com/yongbowin/nlp-papernotes/tree/master/books/word2vec_math_theories.pdf)》
- 《[TensorFlow2深度学习](https://github.com/yongbowin/nlp-papernotes/tree/master/books/TensorFlow2深度学习.pdf)》 \[[code](https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book)\]